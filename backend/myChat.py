import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv
# API key Gemini
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# JSON Schema cho structured output
json_schema = {
  "title": "ToolInfoSchema",
  "type": "object",
  "properties": {
    "intro": {
      "type": "string",
      "description": "Ph·∫£n h·ªìi ng∆∞·ªùi d√πng. Kh√¥ng ch√†o h·ªèi"
    },
    "recommended_tools": {
      "type": "array",
      "description": "Danh s√°ch c√¥ng c·ª• ƒë·ªÅ xu·∫•t",
      "items": {
        "type": "object",
        "properties": {
          "name": { "type": "string", "description": "T√™n c√¥ng c·ª•" },
          "category": { "type": "string", "description": "Danh m·ª•c c√¥ng c·ª•" },
          "description": { "type": "string", "description": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ c√¥ng c·ª•" },
          "url": { "type": "string", "description": "URL ch√≠nh th·ª©c c·ªßa c√¥ng c·ª•" },
          "quick_guide": {
            "type": "array",
            "description": "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng nhanh",
            "items": { "type": "string" }
          },
          "setup_time": { "type": "string", "description": "Th·ªùi gian thi·∫øt l·∫≠p" },
          "difficulty_level": { "type": "string", "description": "M·ª©c ƒë·ªô kh√≥" },
          "advantages": {
            "type": "array",
            "description": "∆Øu ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "disadvantages": {
            "type": "array",
            "description": "Nh∆∞·ª£c ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "pricing": { "type": "string", "description": "Th√¥ng tin gi√° c·∫£" },
          "best_for": { "type": "string", "description": "Ph√π h·ª£p cho ai" }
        },
        "required": [
          "name", "category", "description", "url", "quick_guide",
          "setup_time", "difficulty_level", "advantages", "disadvantages",
          "pricing", "best_for"
        ]
      }
    },
    "comparison": {
      "type": "array",
      "description": "So s√°nh c√°c c√¥ng c·ª•",
      "items": { "type": "string" }
    },
    "final_recommendation": {
      "type": "array",
      "description": "L·ªùi khuy√™n cu·ªëi c√πng",
      "items": { "type": "string" }
    },
    "next_steps": {
      "type": "array",
      "description": "C√°c b∆∞·ªõc ti·∫øp theo",
      "items": { "type": "string" }
    }
  },
  "required": ["intro", "recommended_tools", "comparison", "final_recommendation", "next_steps"]
}

class TechConsultant:
    def __init__(self, model="gemini-2.5-flash", temperature=0):
        # S·ª≠ d·ª•ng json_schema v·ªõi structured output
        self.model = ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            max_output_tokens=None,
            timeout=None,
            max_retries=3,
        ).with_structured_output(json_schema, method="json_mode")
        
        # System message chi ti·∫øt
        system_message = SystemMessage(content="""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá tr√™n Internet.

NHI·ªÜM V·ª§:
- Ph√¢n t√≠ch nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng
- ƒê·ªÅ xu·∫•t 3 c√¥ng c·ª• ph√π h·ª£p nh·∫•t  (c√≥ th·ªÉ √≠t h∆°n n·∫øu kh√¥ng t√¨m th·∫•y)
- So s√°nh chi ti·∫øt ∆∞u/nh∆∞·ª£c ƒëi·ªÉm
- ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ 
- C√°c b∆∞·ªõc ti·∫øp theo ch·ªâ c·∫ßn li·ªát k√™ (kh√¥ng c·∫ßn ti√™u ƒë·ªÅ)
- ·ªû comparison m·ªói c√¥ng c·ª• ph·∫£i l√† m·ªôt m·ª•c ri√™ng bi·ªát kh√¥ng ƒë∆∞·ª£c g·ªôp l·∫°i so s√°nh chung
- Kh√¥ng ƒë∆∞·ª£c thi·∫øu c√°c tr∆∞·ªùng trong JSON tr·∫£ v·ªÅ
- Kh√¥ng s·ª≠ d·ª•ng Markdown
- Cung c·∫•p h∆∞·ªõng d·∫´n b∆∞·ªõc ƒë·∫ßu

Lƒ®NH V·ª∞C CHUY√äN M√îN:
- Web Development (Frontend, Backend, Full-stack)
- Mobile Development (iOS, Android, Cross-platform)  
- Design & UI/UX (Figma, Adobe, Canva...)
- Project Management (Trello, Notion, Asana...)
- Marketing & Business (Analytics, Social Media...)
- Data Analysis & AI Tools
- DevOps & Cloud Services

NGUY√äN T·∫ÆC T∆Ø V·∫§N:
1. ∆Øu ti√™n c√¥ng c·ª• mi·ªÖn ph√≠ ho·∫∑c freemium
2. Ph√π h·ª£p v·ªõi tr√¨nh ƒë·ªô ng∆∞·ªùi d√πng (beginner/intermediate/advanced)
3. C√≥ c·ªông ƒë·ªìng h·ªó tr·ª£ t·ªët
4. D·ªÖ h·ªçc v√† tri·ªÉn khai nhanh
5. Ph·ªï bi·∫øn t·∫°i Vi·ªát Nam

B·∫ÆT BU·ªòC: Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá theo schema sau, kh√¥ng thi·∫øu b·∫•t k·ª≥ field n√†o.
N·∫øu kh√¥ng ch·∫Øc gi√° tr·ªã, h√£y tr·∫£ v·ªÅ chu·ªói `"Unknown"` ho·∫∑c m·∫£ng r·ªóng `[]`, KH√îNG ƒë∆∞·ª£c b·ªè qua field.

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
""")        
        self.messages = [
            system_message,
            HumanMessage(content="Ch√†o anh/ch·ªã! Em c·∫ßn t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p."),
            AIMessage(content="Xin ch√†o! T√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n t√¨m ki·∫øm c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p. H√£y chia s·∫ª v·ªõi t√¥i v·ªÅ d·ª± √°n, m·ª•c ti√™u v√† y√™u c·∫ßu c·ª• th·ªÉ nh√©!")
        ]

    def ask(self, question):
        """ƒê·∫∑t c√¢u h·ªèi t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá"""
        # L√†m gi√†u c√¢u h·ªèi v·ªõi context
        enhanced_question = f"""
C√¢u h·ªèi: {question}

"""
        self.messages.append(HumanMessage(content=enhanced_question))
        
        try:
            # G·ªçi AI v·ªõi structured output
            response = self.model.invoke(self.messages)
            print("[TOOLS] üí° Raw response:", response)
            # Validate v√† clean response
            validated_response = self._validate_response(response)
            print("[TOOLS] ‚úÖ Validated response:", type(validated_response))
            # L∆∞u conversation history
            summary = f"ƒê√£ t∆∞ v·∫•n {len(validated_response['recommended_tools'])} c√¥ng c·ª• cho: {question[:50]}..."
            self.messages.append(AIMessage(content=summary))
            
            return validated_response
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            
            # Fallback response
            fallback_response = {
                            "intro": "Hi·ªán t·∫°i h·ªá th·ªëng ƒëang g·∫∑p l·ªói!",
                            "recommended_tools": [{
                                "name": "L·ªói h·ªá th·ªëng",
                                "category": "Error",
                                "description": f"ƒê√£ x·∫£y ra l·ªói: {str(e)[:100]}...",
                                "url": "",
                                "quick_guide": [],
                                "setup_time": "Unknown",
                                "difficulty_level": "Unknown",
                                "advantages": [],
                                "disadvantages": [],
                                "pricing": "Unknown",
                                "best_for": "Unknown"
                            }],
                            "comparison": [],
                            "final_recommendation": ["Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ƒë·∫∑t c√¢u h·ªèi kh√°c."],
                            "next_steps": ["Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng", "Th·ª≠ l·∫°i sau 5 ph√∫t", "Li√™n h·ªá h·ªó tr·ª£ n·∫øu l·ªói ti·∫øp t·ª•c"]
                        }
            
            self.messages.append(AIMessage(content=f"ƒê√£ x·∫£y ra l·ªói: {str(e)[:50]}..."))
            return fallback_response

    def _validate_response(self, response):
        """Validate v√† l√†m s·∫°ch response t·ª´ AI"""
        try:
            # N·∫øu response l√† dict (chu·∫©n structured output)
            if isinstance(response, dict):
                return response
            else:
                return response.dict()  # Chuy·ªÉn sang dict n·∫øu l√† pydantic model
        except Exception as e:
            print(f"üü° Validation error: {e}")
            return {
                "intro": "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi!",
                "recommended_tools": [{
                    "name": "L·ªói validation",
                    "category": "Error",
                    "description": str(e)[:100],
                    "url": "",
                    "quick_guide": [],
                    "setup_time": "Unknown",
                    "difficulty_level": "Unknown",
                    "advantages": [],
                    "disadvantages": [],
                    "pricing": "Unknown",
                    "best_for": "Unknown"
                }],
                "comparison": [],
                "final_recommendation": "Vui l√≤ng th·ª≠ l·∫°i v·ªõi c√¢u h·ªèi kh√°c",
                "next_steps": ["Ki·ªÉm tra input", "Th·ª≠ l·∫°i", "Li√™n h·ªá h·ªó tr·ª£"]
            }

    def reset_conversation(self):
        """Reset cu·ªôc tr√≤ chuy·ªán"""
        system_msg = self.messages[0]
        self.messages = [
            system_msg,
            HumanMessage(content="Ch√†o anh/ch·ªã! Em c·∫ßn t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p."),
            AIMessage(content="Xin ch√†o! T√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n t√¨m ki·∫øm c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p. H√£y chia s·∫ª v·ªõi t√¥i v·ªÅ d·ª± √°n, m·ª•c ti√™u v√† y√™u c·∫ßu c·ª• th·ªÉ nh√©!")
        ]

    def get_conversation_summary(self):
        """L·∫•y t√≥m t·∫Øt cu·ªôc tr√≤ chuy·ªán"""
        human_msgs = [msg for msg in self.messages if isinstance(msg, HumanMessage)]
        return f"ƒê√£ c√≥ {len(human_msgs)} c√¢u h·ªèi trong cu·ªôc tr√≤ chuy·ªán n√†y"
    
    def general_chat_with_memory(self, question: str) -> str:
        """
        Tr·∫£ l·ªùi c√°c c√¢u h·ªèi chat b√¨nh th∆∞·ªùng (small talk, h·ªèi th√¥ng tin, v.v.)
        nh∆∞ng C√ì s·ª≠ d·ª•ng l·∫°i l·ªãch s·ª≠ self.messages l√†m context chung.
        """
        # System ri√™ng cho ch·∫ø ƒë·ªô chat th∆∞·ªùng (kh√¥ng JSON)
        chat_system = SystemMessage(content="""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán h·ªó tr·ª£ ng∆∞·ªùi d√πng b·∫±ng ti·∫øng Vi·ªát.

B·ªêI C·∫¢NH:
- B·∫°n ƒëang tr√≤ chuy·ªán li√™n t·ª•c v·ªõi ng∆∞·ªùi d√πng trong C√ôNG M·ªòT PHI√äN.
- B·∫°n c√≥ th·ªÉ tham chi·∫øu l·∫°i nh·ªØng g√¨ ng∆∞·ªùi d√πng ƒë√£ h·ªèi / b·∫°n ƒë√£ tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥
  trong phi√™n hi·ªán t·∫°i n·∫øu ƒëi·ªÅu ƒë√≥ gi√∫p c√¢u tr·∫£ l·ªùi t·ª± nhi√™n h∆°n.

Y√äU C·∫¶U:
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, b√°m s√°t c√¢u h·ªèi hi·ªán t·∫°i.
- Kh√¥ng tr·∫£ v·ªÅ JSON, ch·ªâ l√† vƒÉn b·∫£n thu·∫ßn.
- Kh√¥ng c·∫ßn nh·∫Øc l·∫°i to√†n b·ªô l·ªãch s·ª≠, ch·ªâ li√™n h·ªá khi th·ª±c s·ª± c·∫ßn thi·∫øt.
""")

        # L·∫•y l·ªãch s·ª≠ hi·ªán t·∫°i nh∆∞ng b·ªè system message g·ªëc (d√†nh cho t∆∞ v·∫•n c√¥ng c·ª•)
        history_without_system = [
            msg for msg in self.messages
            if not isinstance(msg, SystemMessage)
        ]

        # X√¢y d·ª±ng list messages g·ª≠i l√™n model chat th∆∞·ªùng
        messages = [
            chat_system,
            *history_without_system,
            HumanMessage(content=question)
        ]

        # G·ªçi model chat th∆∞·ªùng v·ªõi full context
        resp = _general_chat_model.invoke(messages)

        try:
            reply_text = resp.content
        except AttributeError:
            reply_text = str(resp)

        # 
        print("[CHAT] üí° Response:", reply_text)

        # L∆∞u ti·∫øp ƒëo·∫°n h·ªôi tho·∫°i n√†y v√†o self.messages ƒë·ªÉ l·∫ßn sau c√≤n nh·ªõ
        self.messages.append(HumanMessage(content=question))
        self.messages.append(AIMessage(content=reply_text))

        return reply_text


# Global instance ƒë·ªÉ duy tr√¨ conversation
_tech_consultant = None

# L·∫•y ho·∫∑c t·∫°o consultant instance
def get_consultant():
    global _tech_consultant
    if _tech_consultant is None:
        _tech_consultant = TechConsultant()
    return _tech_consultant

# Interface ƒë∆°n gi·∫£n ƒë·ªÉ h·ªèi v·ªÅ c√¥ng c·ª• c√¥ng ngh·ªá
def ask_for_tools(question):
    consultant = get_consultant()
    return consultant.ask(question)

# Reset cu·ªôc t∆∞ v·∫•n
def reset_consultation():
    global _tech_consultant
    if _tech_consultant:
        _tech_consultant.reset_conversation()
        return "‚úÖ ƒê√£ reset cu·ªôc t∆∞ v·∫•n!"
    return "‚ö†Ô∏è Ch∆∞a c√≥ cu·ªôc t∆∞ v·∫•n n√†o ƒë·ªÉ reset"

# L·∫•y t√≥m t·∫Øt cu·ªôc t∆∞ v·∫•n
def get_consultation_summary():
    consultant = get_consultant()
    return consultant.get_conversation_summary()

# Ghi l·∫°i c√¢u h·ªèi TOOLS v√†o file testcases.txt
def log_tool_query(query, path="testcases.txt"):
    try:
        with open(path, "a", encoding="utf-8") as f:
            f.write(query.strip() + "\n")
    except Exception as e:
        print(f"[LOG] Failed to write test case: {e}")

# X·ª≠ l√Ω query t·ª´ ng∆∞·ªùi d√πng
def handle_query(query):
    try:
        try:
            if is_tool_query(query):
                log_tool_query(query)
        except Exception as e:
            print(f"[LOG] Error during is_tool_query check: {e}")

        result = ask_for_tools(query)
        return result
    except Exception as e:
        return {"error": str(e)}
    
'''    # N·∫øu response l√† string JSON
            if isinstance(response, str):
                return json.loads(response)

            # N·∫øu kh√¥ng h·ª£p l·ªá
            return {
                "recommended_tools": [],
                "comparison": [],
                "final_recommendation": "Ph·∫£n h·ªìi kh√¥ng h·ª£p l·ªá",
                "next_steps": ["Th·ª≠ l·∫°i c√¢u h·ªèi"]
            }
            '''

# Model chuy√™n d√πng ƒë·ªÉ PH√ÇN LO·∫†I query (TOOLS / CHAT)
_mode_classifier_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    max_output_tokens=None,
    timeout=None,
    max_retries=3,
)

def is_tool_query(query: str) -> bool:
    """
    D√πng Gemini ƒë·ªÉ ph√¢n lo·∫°i xem c√¢u h·ªèi c√≥ ƒëang c·∫ßn t∆∞ v·∫•n c√¥ng c·ª• hay kh√¥ng.
    Tr·∫£ v·ªÅ:
      - True  => query l√† d·∫°ng "t√¨m c√¥ng c·ª•"
      - False => query l√† chat b√¨nh th∆∞·ªùng (ch√†o h·ªèi, h·ªèi th√¥ng tin chung, small talk,...)
    """
    if not query:
        return False

    classification_prompt = f"""
B·∫°n l√† m·ªôt m√¥-ƒëun PH√ÇN LO·∫†I c√¢u h·ªèi cho h·ªá th·ªëng t∆∞ v·∫•n c√¥ng c·ª•.

M·ª§C ƒê√çCH PH√ÇN LO·∫†I

H·ªá th·ªëng c√≥ 2 ch·∫ø ƒë·ªô:
1) TOOLS: D√πng khi ng∆∞·ªùi d√πng mu·ªën ƒë∆∞·ª£c T√åM / CH·ªåN / G·ª¢I √ù / GI·ªöI THI·ªÜU / SO S√ÅNH / L·ª∞A CH·ªåN (ho·∫∑c ng·ªØ c·∫£nh t∆∞∆°ng t·ª±)
   - c√¥ng c·ª•, ph·∫ßn m·ªÅm, ·ª©ng d·ª•ng, app, web, n·ªÅn t·∫£ng, ng√¥n ng·ªØ, d·ªãch v·ª•, kho√° h·ªçc online,...
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: TOOLS
2) CHAT: D√πng cho c√°c c√¢u h·ªèi c√≤n l·∫°i (ch√†o h·ªèi, h·ªèi ki·∫øn th·ª©c chung, small talk, h∆∞·ªõng d·∫´n nhanh,...).
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: CHAT

L∆ØU √ù QUAN TR·ªåNG:
- Ch·ªâ tr·∫£ l·ªùi ƒë√∫ng m·ªôt trong hai t·ª´ kh√≥a TOOLS ho·∫∑c CHAT, KH√îNG ƒë∆∞·ª£c th√™m g√¨ kh√°c.

B√¢y gi·ªù h√£y ph√¢n lo·∫°i c√¢u sau:

User: "{query}"
Assistant:
"""
    resp = _mode_classifier_model.invoke(classification_prompt)

    try:
        text = resp.content.strip().upper()
    except AttributeError:
        text = str(resp).strip().upper()

    # Debug cho d·ªÖ theo d√µi server log
    print(f"‚ùî Request: {query!r} -> Type: {text!r}")

    # N·∫øu model tr·∫£ ƒë√∫ng TOOLS th√¨ coi l√† t√¨m c√¥ng c·ª•
    if "TOOLS" in text:
        return True

    # M·∫∑c ƒë·ªãnh l√† CHAT
    return False

# Model cho chat b√¨nh th∆∞·ªùng (kh√¥ng structured_output)
_general_chat_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    max_output_tokens=None,
    timeout=None,
    max_retries=3,
)

def general_chat(query: str) -> str:
    """
    Tr·∫£ l·ªùi c√°c c√¢u h·ªèi b√¨nh th∆∞·ªùng (ch√†o h·ªèi, gi·ªõi thi·ªáu, small talk,...)
    nh∆∞ng d√πng CHUNG l·ªãch s·ª≠ h·ªôi tho·∫°i c·ªßa TechConsultant.
    """
    consultant = get_consultant()
    return consultant.general_chat_with_memory(query)

# Sample questions for testing
SAMPLE_QUESTIONS = {
    "web_dev": "T√¥i mu·ªën t·∫°o website b√°n h√†ng online, budget 2-3 tri·ªáu",
    "mobile_app": "C·∫ßn ph√°t tri·ªÉn app mobile cho startup, c√≥ kinh nghi·ªám React",
    "design": "T√¥i l√† h·ªçc sinh c·∫ßn c√¥ng c·ª• thi·∫øt k·∫ø poster v√† logo mi·ªÖn ph√≠",
    "project_mgmt": "Team 5 ng∆∞·ªùi c·∫ßn qu·∫£n l√Ω d·ª± √°n ph·∫ßn m·ªÅm hi·ªáu qu·∫£",
    "data_analysis": "Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng cho shop online nh·ªè"
}