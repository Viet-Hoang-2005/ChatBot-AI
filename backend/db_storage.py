import faiss
import numpy as np
import sqlite3
import json
from sentence_transformers import SentenceTransformer

DB_PATH = "query_cache.db"
EMBEDDING_MODEL = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# === Chu·∫©n b·ªã DB ===
conn = sqlite3.connect(DB_PATH)
c = conn.cursor()
c.execute("""
CREATE TABLE IF NOT EXISTS cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    query TEXT,
    embedding BLOB,
    response_json TEXT
)
""")
conn.commit()
conn.close()

# === FAISS index (384 chi·ªÅu) ===
index = faiss.IndexFlatIP(384)
id_map = []  # √°nh x·∫° gi·ªØa v·ªã tr√≠ trong FAISS v√† id trong DB

def normalize(v):
    return v / np.linalg.norm(v)

def add_to_cache(query, response_dict):
    vec = EMBEDDING_MODEL.encode([query])[0]
    vec = normalize(vec)
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("INSERT INTO cache (query, embedding, response_json) VALUES (?, ?, ?)",
              (query, vec.tobytes(), json.dumps(response_dict, ensure_ascii=False)))
    new_id = c.lastrowid
    conn.commit()
    conn.close()
    index.add(np.array([vec]).astype("float32"))
    id_map.append(new_id)

def search_similar(query, threshold):
    """
    T√¨m ki·∫øm cache v·ªõi threshold nghi√™m ng·∫∑t h∆°n
    
    G·ª£i √Ω threshold:
    - 0.95-0.98: R·∫•t nghi√™m ng·∫∑t - ch·ªâ match c√¢u g·∫ßn nh∆∞ gi·ªëng h·ªát
    - 0.90-0.94: Nghi√™m ng·∫∑t - c√¢u h·ªèi ph·∫£i r·∫•t t∆∞∆°ng ƒë·ªìng
    - 0.85-0.89: Trung b√¨nh - cho ph√©p bi·∫øn th·ªÉ nh·∫π
    - 0.80-0.84: R·ªông - match nhi·ªÅu c√¢u t∆∞∆°ng t·ª±
    """
    vec = EMBEDDING_MODEL.encode([query])[0]
    vec = normalize(vec).astype("float32")

    if index.ntotal == 0:
        # load DB v√†o FAISS
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("SELECT id, embedding FROM cache")
        rows = c.fetchall()
        for r in rows:
            emb = np.frombuffer(r[1], dtype=np.float32)
            index.add(np.array([emb]))
            id_map.append(r[0])
        conn.close()

    D, I = index.search(np.array([vec]), k=1)
    score = D[0][0]
    
    # Log ƒë·ªÉ debug (c√≥ th·ªÉ b·ªè sau khi test xong)
    print(f"üîç Query: '{query[:50]}...' | Similarity score: {score:.4f} | Threshold: {threshold}")
    
    if score >= threshold and I[0][0] >= 0:
        matched_id = id_map[I[0][0]]
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("SELECT query, response_json FROM cache WHERE id=?", (matched_id,))
        row = c.fetchone()
        conn.close()
        if row:
            print(f"‚úÖ Found in cache: '{row[0][:50]}...' | score: {score:.4f}")
            return row[0], json.loads(row[1]), score
    
    print(f"‚ùå No cache match (score {score:.4f} < threshold {threshold})")
    return None, None, score


def clear_cache():
    """X√≥a to√†n b·ªô cache (d√πng khi c·∫ßn reset)"""
    global index, id_map
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM cache")
    conn.commit()
    conn.close()
    
    # Reset FAISS index
    index = faiss.IndexFlatIP(384)
    id_map = []
    print("üóëÔ∏è Cache ƒë√£ ƒë∆∞·ª£c x√≥a ho√†n to√†n")


def get_cache_stats():
    """Th·ªëng k√™ cache hi·ªán t·∫°i"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM cache")
    count = c.fetchone()[0]
    conn.close()
    return {
        "total_cached_queries": count,
        "faiss_index_size": index.ntotal
    }