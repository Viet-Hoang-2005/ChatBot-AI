import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv

# API key Gemini
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# 1. C·∫§U H√åNH H·∫∞NG S·ªê
# Ch·ªâ nh·ªõ 20 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ ti·∫øt ki·ªám token
HISTORY_WINDOW_SIZE = 20

# JSON Schema cho ph·∫£n h·ªìi t∆∞ v·∫•n c√¥ng c·ª•
JSON_SCHEMA = {
  "title": "ToolInfoSchema",
  "type": "object",
  "properties": {
    "intro": {
      "type": "string",
      "description": "Ph·∫£n h·ªìi ng∆∞·ªùi d√πng"
    },
    "recommended_tools": {
      "type": "array",
      "description": "Danh s√°ch c√¥ng c·ª• ƒë·ªÅ xu·∫•t",
      "items": {
        "type": "object",
        "properties": {
          "name": { "type": "string", "description": "T√™n c√¥ng c·ª•" },
          "category": { "type": "string", "description": "Danh m·ª•c c√¥ng c·ª•" },
          "description": { "type": "string", "description": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ c√¥ng c·ª•" },
          "url": { "type": "string", "description": "URL ch√≠nh th·ª©c c·ªßa c√¥ng c·ª•" },
          "quick_guide": {
            "type": "array",
            "description": "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng nhanh",
            "items": { "type": "string" }
          },
          "setup_time": { "type": "string", "description": "Th·ªùi gian thi·∫øt l·∫≠p" },
          "difficulty_level": { "type": "string", "description": "M·ª©c ƒë·ªô kh√≥" },
          "advantages": {
            "type": "array",
            "description": "∆Øu ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "disadvantages": {
            "type": "array",
            "description": "Nh∆∞·ª£c ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "pricing": { "type": "string", "description": "Th√¥ng tin gi√° c·∫£" },
          "best_for": { "type": "string", "description": "Ph√π h·ª£p cho ai" }
        },
        "required": [
          "name", "category", "description", "url", "quick_guide",
          "setup_time", "difficulty_level", "advantages", "disadvantages",
          "pricing", "best_for"
        ]
      }
    },
    "comparison": {
      "type": "array",
      "description": "So s√°nh c√°c c√¥ng c·ª•",
      "items": { "type": "string" }
    },
    "final_recommendation": {
      "type": "array",
      "description": "L·ªùi khuy√™n cu·ªëi c√πng",
      "items": { "type": "string" }
    },
    "next_steps": {
      "type": "array",
      "description": "C√°c b∆∞·ªõc ti·∫øp theo",
      "items": { "type": "string" }
    }
  },
  "required": ["intro", "recommended_tools", "comparison", "final_recommendation", "next_steps"]
}

BASE_TOOL_PROMPT = """ B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá tr√™n Internet.

NHI·ªÜM V·ª§:
- Ph√¢n t√≠ch nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng
- ƒê·ªÅ xu·∫•t 3 c√¥ng c·ª• ph√π h·ª£p nh·∫•t (c√≥ th·ªÉ √≠t h∆°n n·∫øu kh√¥ng t√¨m th·∫•y)
- So s√°nh chi ti·∫øt ∆∞u/nh∆∞·ª£c ƒëi·ªÉm
- ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ 
- C√°c b∆∞·ªõc ti·∫øp theo ch·ªâ c·∫ßn li·ªát k√™ (kh√¥ng c·∫ßn ti√™u ƒë·ªÅ)
- ·ªû comparison m·ªói c√¥ng c·ª• ph·∫£i l√† m·ªôt m·ª•c ri√™ng bi·ªát kh√¥ng ƒë∆∞·ª£c g·ªôp l·∫°i so s√°nh chung
- Tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng s·ª≠ d·ª•ng Markdown
- Ng√¥n ng·ªØ tr·∫£ l·ªùi m·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát

NGUY√äN T·∫ÆC T∆Ø V·∫§N:
1. ∆Øu ti√™n c√¥ng c·ª• ph√π h·ª£p v·ªõi tr√¨nh ƒë·ªô ng∆∞·ªùi d√πng
2. C√≥ c·ªông ƒë·ªìng h·ªó tr·ª£ t·ªët
3. D·ªÖ h·ªçc v√† tri·ªÉn khai nhanh
4. Ph·ªï bi·∫øn r·ªông r√£i tr√™n th·ªã tr∆∞·ªùng

B·∫ÆT BU·ªòC: Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá theo schema sau, kh√¥ng thi·∫øu b·∫•t k·ª≥ field n√†o.
N·∫øu kh√¥ng ch·∫Øc gi√° tr·ªã, h√£y tr·∫£ v·ªÅ chu·ªói "Unknown" ho·∫∑c m·∫£ng r·ªóng [], KH√îNG ƒë∆∞·ª£c b·ªè qua field.
"""

BASE_CHAT_PROMPT = """ B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá tr√™n Internet.

B·ªêI C·∫¢NH:
- B·∫°n ƒëang tr√≤ chuy·ªán li√™n t·ª•c v·ªõi ng∆∞·ªùi d√πng trong c√πng m·ªôt phi√™n.
- B·∫°n c√≥ th·ªÉ tham chi·∫øu l·∫°i nh·ªØng g√¨ ng∆∞·ªùi d√πng ƒë√£ h·ªèi / b·∫°n ƒë√£ tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥
  trong phi√™n hi·ªán t·∫°i n·∫øu ƒëi·ªÅu ƒë√≥ gi√∫p c√¢u tr·∫£ l·ªùi t·ª± nhi√™n h∆°n.

Y√äU C·∫¶U:
- Ng√¥n ng·ªØ tr·∫£ l·ªùi m·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát, tr·∫£ l·ªùi b√°m s√°t c√¢u h·ªèi hi·ªán t·∫°i.
- Kh√¥ng c·∫ßn nh·∫Øc l·∫°i to√†n b·ªô l·ªãch s·ª≠, ch·ªâ li√™n h·ªá khi th·ª±c s·ª± c·∫ßn thi·∫øt.
"""

# 2. C·∫§U H√åNH MODEL GEMINI
_mode_classifier_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, max_retries=3)
_general_chat_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5, max_retries=3)

# 3. CLASS TECH CONSULTANT
class TechConsultant:
    # Kh·ªüi t·∫°o bot t∆∞ v·∫•n c√¥ng c·ª•
    def __init__(self, model="gemini-2.5-flash", temperature=0):
        # Thi·∫øt l·∫≠p model v·ªõi JSON Schema
        self.model = ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            max_retries=3,
        ).with_structured_output(JSON_SCHEMA, method="json_mode")
        
        # Thi·∫øt l·∫≠p profile v√† chat history ban ƒë·∫ßu
        self.current_profile = None
        self.chat_history = []
     
    # T·∫°o chu·ªói context t·ª´ profile hi·ªán t·∫°i
    def _get_profile_context(self):
        if not self.current_profile:
            return ""
            
        p = self.current_profile
        return f"""
TH√îNG TIN NG∆Ø·ªúI D√ôNG:
- H·ªç t√™n: {p.get('fullName', 'B·∫°n')}
- ƒê·ªô tu·ªïi: {p.get('ageGroup', '')}
- Ngh·ªÅ nghi·ªáp: {p.get('profession', 'Ng∆∞·ªùi d√πng')}
- Qu·ªëc gia: {p.get('country', '')}
- M√¥ t·∫£ th√™m: {p.get('description', '')}

Y√äU C·∫¶U C√Å NH√ÇN H√ìA:
- H√£y g·ªçi ng∆∞·ªùi d√πng b·∫±ng t√™n "{p.get('fullName', 'B·∫°n')}" n·∫øu c√≥ th·ªÉ.
- V√¨ ng∆∞·ªùi d√πng l√† "{p.get('profession', 'Ng∆∞·ªùi d√πng')}" ({p.get('ageGroup', '')}), h√£y ƒëi·ªÅu ch·ªânh t·ª´ ng·ªØ cho ph√π h·ª£p.
  + N·∫øu l√† ng∆∞·ªùi m·ªõi/h·ªçc sinh: Gi·∫£i th√≠ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ s√¢u.
  + N·∫øu l√† chuy√™n gia/IT: D√πng thu·∫≠t ng·ªØ chuy√™n ng√†nh, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
- C√¢n nh·∫Øc c√°c c√¥ng c·ª• ph·ªï bi·∫øn t·∫°i {p.get('country', '')}.
"""

    # X√¢y d·ª±ng danh s√°ch messages ho√†n ch·ªânh v·ªõi l·ªãch s·ª≠ v√† profile
    def _build_messages(self, system_prompt_content, question):
        # T·∫°o System Message ƒë·ªông (k·∫øt h·ª£p prompt g·ªëc + profile)
        full_system_prompt = system_prompt_content + "\n" + self._get_profile_context()
        
        # L·∫•y l·ªãch s·ª≠ g·∫ßn nh·∫•t (Sliding Window)
        recent_history = self.chat_history[-HISTORY_WINDOW_SIZE:] if self.chat_history else []
        
        # Tr·∫£ v·ªÅ danh s√°ch messages ho√†n ch·ªânh ƒë·ªÉ g·ª≠i cho Gemini
        return [SystemMessage(content=full_system_prompt)] + recent_history + [HumanMessage(content=question)]

    # H√†m c·∫≠p nh·∫≠t System Prompt d·ª±a tr√™n Profile m·ªõi nh·∫•t
    def update_system_prompt(self, profile):        
        self.current_profile = profile
    
    # H√†m ƒë·∫∑t l·∫°i h·ªôi tho·∫°i
    def reset_conversation(self):
        self.chat_history = []

    # H√†m x·ª≠ l√Ω t∆∞ v·∫•n c√¥ng c·ª• (JSON)
    def ask(self, question):
        try:
            # T·∫°o messages chuy√™n cho Tools
            messages = self._build_messages(
                system_prompt_content=BASE_TOOL_PROMPT,
                question=f"C√¢u h·ªèi: {question}"
            )

            # G·ªçi model ƒë·ªÉ l·∫•y ph·∫£n h·ªìi cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
            response = self.model.invoke(messages)
            
            print(f"üí° [TOOLS] Response generated: {response}...")
            
            # X√°c th·ª±c ph·∫£n h·ªìi d·∫°ng dict
            validated_response = response if isinstance(response, dict) else response.dict()
            print("‚úÖ [TOOLS] Validated response:", type(validated_response))

            # Tr√≠ch xu·∫•t th√¥ng tin ch√≠nh ƒë·ªÉ l∆∞u v√†o l·ªãch s·ª≠
            intro_text = validated_response.get('intro', '')
            tools = validated_response.get('recommended_tools', [])
            tool_names = ", ".join([t.get('name', 'C√¥ng c·ª•') for t in tools])
            
            # L∆∞u User Message
            self.chat_history.append(HumanMessage(content=question))

            # L∆∞u AI Message (Intro + Danh s√°ch t√™n)
            summary_for_history = f"{intro_text}\n(ƒê√£ ƒë·ªÅ xu·∫•t c√°c c√¥ng c·ª•: {tool_names})"
            self.chat_history.append(AIMessage(content=summary_for_history))
            
            # Tr·∫£ v·ªÅ ph·∫£n h·ªìi ƒë√£ x√°c th·ª±c
            return validated_response
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            
            # L∆∞u l·ªói v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i
            self.chat_history.append(AIMessage(content=f"L·ªói h·ªá th·ªëng: {str(e)[:50]}"))

            # Tr·∫£ v·ªÅ ph·∫£n h·ªìi m·∫∑c ƒë·ªãnh khi l·ªói
            return self._get_fallback_response(str(e))
        
    # H√†m x·ª≠ l√Ω chat th∆∞·ªùng
    def general_chat_with_memory(self, question: str) -> str:
        try:
            # T·∫°o messages chuy√™n cho Chat
            messages = self._build_messages(
                system_prompt_content=BASE_CHAT_PROMPT,
                question=question
            )

            # G·ªçi model chat th∆∞·ªùng
            resp = _general_chat_model.invoke(messages)
            reply_text = resp.content if hasattr(resp, 'content') else str(resp)
        
            print(f"üí° [CHAT] Response generated: {reply_text[:50]}...")
        
            # L∆∞u l·ªãch s·ª≠
            self.chat_history.append(HumanMessage(content=question))
            self.chat_history.append(AIMessage(content=reply_text))
            
            return reply_text
        except Exception as e:
            return "Xin l·ªói, hi·ªán t·∫°i t√¥i kh√¥ng th·ªÉ ph·∫£n h·ªìi. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Ph·∫£n h·ªìi m·∫∑c ƒë·ªãnh khi l·ªói x·∫£y ra
    def _get_fallback_response(self, error_msg):
        return {
            "intro": "H·ªá th·ªëng ƒëang g·∫∑p l·ªói!",
            "recommended_tools": [],
            "comparison": [],
            "final_recommendation": [],
            "next_steps": []
        }

# 4. QU·∫¢N L√ù SESSIONS T∆Ø V·∫§N
# Kho ch·ª©a c√°c phi√™n l√†m vi·ªác ri√™ng bi·ªát
_active_sessions = {}

# L·∫•y bot ri√™ng c·ªßa session ƒë√≥, n·∫øu ch∆∞a c√≥ th√¨ t·∫°o m·ªõi
def get_consultant(session_id, user_profile=None):
    # S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ sessions
    global _active_sessions
    
    # N·∫øu session ch∆∞a t·ªìn t·∫°i, t·∫°o bot m·ªõi
    if session_id not in _active_sessions:
        print(f"üÜï New session: {session_id}")
        _active_sessions[session_id] = TechConsultant() # Bot m·ªõi s·∫Ω d√πng prompt g·ªëc ·ªü tr√™n
    
    # L·∫•y bot c·ªßa session ƒë√≥
    consultant = _active_sessions[session_id]
    
    # C·∫≠p nh·∫≠t profile n·∫øu c√≥ thay ƒë·ªïi
    if user_profile:
        consultant.update_system_prompt(user_profile)
    
    return consultant

# 5. C√ÅC H√ÄM X·ª¨ L√ù CH√çNH
# H√†m ph√¢n lo·∫°i c√¢u h·ªèi l√† Tools hay Chat
def is_tool_query(query: str) -> bool:
    # N·∫øu c√¢u h·ªèi tr·ªëng, tr·∫£ v·ªÅ False
    if not query: return False
    
    # Prompt ph√¢n lo·∫°i
    prompt = f"""
B·∫°n l√† m·ªôt m√¥-ƒëun PH√ÇN LO·∫†I c√¢u h·ªèi cho h·ªá th·ªëng t∆∞ v·∫•n c√¥ng c·ª•.

H·ªá th·ªëng c√≥ 2 ch·∫ø ƒë·ªô:
1) TOOLS: D√πng khi ng∆∞·ªùi d√πng mu·ªën ƒë∆∞·ª£c T√åM / CH·ªåN / G·ª¢I √ù / GI·ªöI THI·ªÜU / SO S√ÅNH / L·ª∞A CH·ªåN (ho·∫∑c ng·ªØ c·∫£nh t∆∞∆°ng t·ª±)
    cho c√¥ng c·ª•, ph·∫ßn m·ªÅm, ·ª©ng d·ª•ng, app, web, n·ªÅn t·∫£ng, ng√¥n ng·ªØ, d·ªãch v·ª•, kho√° h·ªçc online,...
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: TOOLS
2) CHAT: D√πng cho c√°c c√¢u h·ªèi c√≤n l·∫°i (ch√†o h·ªèi, h·ªèi ki·∫øn th·ª©c chung, small talk, h∆∞·ªõng d·∫´n nhanh,...)
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: CHAT

B√¢y gi·ªù h√£y ph√¢n lo·∫°i c√¢u sau:

User: "{query}"
Assistant:
"""
    try:
        # G·ªçi model ph√¢n lo·∫°i
        resp = _mode_classifier_model.invoke(prompt)
        
        # L·∫•y k·∫øt qu·∫£ v√† chu·∫©n ho√°
        text = (resp.content or "").strip().upper()
        print(f"‚ùî Request: '{query[:50]}...' -> Type: {text}")
        
        # Tr·∫£ v·ªÅ True n·∫øu l√† Tools, False n·∫øu l√† Chat
        return "TOOLS" in text
    except:
        return False

# H√†m x·ª≠ l√Ω t√¨m tool
def handle_query(query, session_id, user_profile=None):
    consultant = get_consultant(session_id, user_profile)
    return consultant.ask(query)

# H√†m x·ª≠ l√Ω chat th∆∞·ªùng
def general_chat(query, session_id, user_profile=None):
    consultant = get_consultant(session_id, user_profile)
    return consultant.general_chat_with_memory(query)

# H√†m reset b·ªô nh·ªõ h·ªôi tho·∫°i c·ªßa session
def reset_consultation(session_id):
    global _active_sessions
    if session_id in _active_sessions:
        _active_sessions[session_id].reset_conversation()
        return f"‚úÖ ƒê√£ reset b·ªô nh·ªõ cho session {session_id}!"
    return "‚ö†Ô∏è Session m·ªõi tinh."