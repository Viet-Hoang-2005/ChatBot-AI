import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv

# API key Gemini
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# --- 1. C·∫§U H√åNH JSON SCHEMA ---
json_schema = {
  "title": "ToolInfoSchema",
  "type": "object",
  "properties": {
    "intro": {
      "type": "string",
      "description": "Ph·∫£n h·ªìi ng∆∞·ªùi d√πng. Kh√¥ng ch√†o h·ªèi"
    },
    "recommended_tools": {
      "type": "array",
      "description": "Danh s√°ch c√¥ng c·ª• ƒë·ªÅ xu·∫•t",
      "items": {
        "type": "object",
        "properties": {
          "name": { "type": "string", "description": "T√™n c√¥ng c·ª•" },
          "category": { "type": "string", "description": "Danh m·ª•c c√¥ng c·ª•" },
          "description": { "type": "string", "description": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ c√¥ng c·ª•" },
          "url": { "type": "string", "description": "URL ch√≠nh th·ª©c c·ªßa c√¥ng c·ª•" },
          "quick_guide": {
            "type": "array",
            "description": "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng nhanh",
            "items": { "type": "string" }
          },
          "setup_time": { "type": "string", "description": "Th·ªùi gian thi·∫øt l·∫≠p" },
          "difficulty_level": { "type": "string", "description": "M·ª©c ƒë·ªô kh√≥" },
          "advantages": {
            "type": "array",
            "description": "∆Øu ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "disadvantages": {
            "type": "array",
            "description": "Nh∆∞·ª£c ƒëi·ªÉm",
            "items": { "type": "string" }
          },
          "pricing": { "type": "string", "description": "Th√¥ng tin gi√° c·∫£" },
          "best_for": { "type": "string", "description": "Ph√π h·ª£p cho ai" }
        },
        "required": [
          "name", "category", "description", "url", "quick_guide",
          "setup_time", "difficulty_level", "advantages", "disadvantages",
          "pricing", "best_for"
        ]
      }
    },
    "comparison": {
      "type": "array",
      "description": "So s√°nh c√°c c√¥ng c·ª•",
      "items": { "type": "string" }
    },
    "final_recommendation": {
      "type": "array",
      "description": "L·ªùi khuy√™n cu·ªëi c√πng",
      "items": { "type": "string" }
    },
    "next_steps": {
      "type": "array",
      "description": "C√°c b∆∞·ªõc ti·∫øp theo",
      "items": { "type": "string" }
    }
  },
  "required": ["intro", "recommended_tools", "comparison", "final_recommendation", "next_steps"]
}
# --- 2. C√ÅC MODEL GEMINI ---
_mode_classifier_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, max_retries=3)
_general_chat_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5, max_retries=3)

# --- 3. CLASS TECH CONSULTANT ---
class TechConsultant:
    def __init__(self, model="gemini-2.5-flash", temperature=0):
        self.model = ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            max_retries=3,
        ).with_structured_output(json_schema, method="json_mode")
        
        self.system_message = SystemMessage(content="""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá tr√™n Internet.

NHI·ªÜM V·ª§:
- Ph√¢n t√≠ch nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng
- ƒê·ªÅ xu·∫•t 3 c√¥ng c·ª• ph√π h·ª£p nh·∫•t  (c√≥ th·ªÉ √≠t h∆°n n·∫øu kh√¥ng t√¨m th·∫•y)
- So s√°nh chi ti·∫øt ∆∞u/nh∆∞·ª£c ƒëi·ªÉm
- ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ 
- C√°c b∆∞·ªõc ti·∫øp theo ch·ªâ c·∫ßn li·ªát k√™ (kh√¥ng c·∫ßn ti√™u ƒë·ªÅ)
- ·ªû comparison m·ªói c√¥ng c·ª• ph·∫£i l√† m·ªôt m·ª•c ri√™ng bi·ªát kh√¥ng ƒë∆∞·ª£c g·ªôp l·∫°i so s√°nh chung
- Kh√¥ng ƒë∆∞·ª£c thi·∫øu c√°c tr∆∞·ªùng trong JSON tr·∫£ v·ªÅ
- Kh√¥ng s·ª≠ d·ª•ng Markdown
- Cung c·∫•p h∆∞·ªõng d·∫´n b∆∞·ªõc ƒë·∫ßu

Lƒ®NH V·ª∞C CHUY√äN M√îN:
- Web Development (Frontend, Backend, Full-stack)
- Mobile Development (iOS, Android, Cross-platform)  
- Design & UI/UX (Figma, Adobe, Canva...)
- Project Management (Trello, Notion, Asana...)
- Marketing & Business (Analytics, Social Media...)
- Data Analysis & AI Tools
- DevOps & Cloud Services

NGUY√äN T·∫ÆC T∆Ø V·∫§N:
1. ∆Øu ti√™n c√¥ng c·ª• mi·ªÖn ph√≠ ho·∫∑c freemium
2. Ph√π h·ª£p v·ªõi tr√¨nh ƒë·ªô ng∆∞·ªùi d√πng (beginner/intermediate/advanced)
3. C√≥ c·ªông ƒë·ªìng h·ªó tr·ª£ t·ªët
4. D·ªÖ h·ªçc v√† tri·ªÉn khai nhanh
5. Ph·ªï bi·∫øn t·∫°i Vi·ªát Nam

B·∫ÆT BU·ªòC: Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá theo schema sau, kh√¥ng thi·∫øu b·∫•t k·ª≥ field n√†o.
N·∫øu kh√¥ng ch·∫Øc gi√° tr·ªã, h√£y tr·∫£ v·ªÅ chu·ªói "Unknown" ho·∫∑c m·∫£ng r·ªóng [], KH√îNG ƒë∆∞·ª£c b·ªè qua field.

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
""")        
        self.reset_conversation()

    def reset_conversation(self):
        self.messages = [
            self.system_message,
            HumanMessage(content="Ch√†o anh/ch·ªã! Em c·∫ßn t∆∞ v·∫•n c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p."),
            AIMessage(content="Xin ch√†o! T√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n t√¨m ki·∫øm c√¥ng c·ª• c√¥ng ngh·ªá ph√π h·ª£p. H√£y chia s·∫ª v·ªõi t√¥i v·ªÅ d·ª± √°n, m·ª•c ti√™u v√† y√™u c·∫ßu c·ª• th·ªÉ nh√©!")
        ]

    def ask(self, question):
        """X·ª≠ l√Ω t∆∞ v·∫•n c√¥ng c·ª• (JSON)"""
        enhanced_question = f"\nC√¢u h·ªèi: {question}\n"
        self.messages.append(HumanMessage(content=enhanced_question))
        
        try:
            response = self.model.invoke(self.messages)
            print("üí° [TOOLS] Response generated: ", response)
            
            # Validate response
            validated_response = response if isinstance(response, dict) else response.dict()
            print("‚úÖ [TOOLS] Validated response:", type(validated_response))

            # L∆∞u t√≥m t·∫Øt
            summary = f"ƒê√£ t∆∞ v·∫•n {len(validated_response.get('recommended_tools', []))} c√¥ng c·ª• cho: {question[:50]}..."
            self.messages.append(AIMessage(content=summary))
            return validated_response
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            self.messages.append(AIMessage(content=f"ƒê√£ x·∫£y ra l·ªói: {str(e)[:50]}..."))
            return self._get_fallback_response(str(e))

    def general_chat_with_memory(self, question: str) -> str:        
        chat_system = SystemMessage(content="""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán h·ªó tr·ª£ ng∆∞·ªùi d√πng b·∫±ng ti·∫øng Vi·ªát.

B·ªêI C·∫¢NH:
- B·∫°n ƒëang tr√≤ chuy·ªán li√™n t·ª•c v·ªõi ng∆∞·ªùi d√πng trong C√ôNG M·ªòT PHI√äN.
- B·∫°n c√≥ th·ªÉ tham chi·∫øu l·∫°i nh·ªØng g√¨ ng∆∞·ªùi d√πng ƒë√£ h·ªèi / b·∫°n ƒë√£ tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥
  trong phi√™n hi·ªán t·∫°i n·∫øu ƒëi·ªÅu ƒë√≥ gi√∫p c√¢u tr·∫£ l·ªùi t·ª± nhi√™n h∆°n.

Y√äU C·∫¶U:
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, b√°m s√°t c√¢u h·ªèi hi·ªán t·∫°i.
- Kh√¥ng c·∫ßn nh·∫Øc l·∫°i to√†n b·ªô l·ªãch s·ª≠, ch·ªâ li√™n h·ªá khi th·ª±c s·ª± c·∫ßn thi·∫øt.
""")

        # L·ªçc b·ªè System Message c·ªßa ph·∫ßn Tools ƒë·ªÉ tr√°nh l·∫´n l·ªôn
        history_context = [msg for msg in self.messages if not isinstance(msg, SystemMessage)]
        
        # T·∫°o context m·ªõi cho chat th∆∞·ªùng
        messages = [chat_system] + history_context + [HumanMessage(content=question)]

        try:
            resp = _general_chat_model.invoke(messages)
            reply_text = resp.content if hasattr(resp, 'content') else str(resp)
            
            print("üí° [CHAT] Response generated: ", reply_text[:50])

            # L∆∞u v√†o l·ªãch s·ª≠ chung ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh cho c·∫£ 2 ch·∫ø ƒë·ªô
            self.messages.append(HumanMessage(content=question))
            self.messages.append(AIMessage(content=reply_text))
            return reply_text
        except Exception as e:
            return "Xin l·ªói, hi·ªán t·∫°i t√¥i kh√¥ng th·ªÉ ph·∫£n h·ªìi. Vui l√≤ng th·ª≠ l·∫°i sau."

    def _get_fallback_response(self, error_msg):
        return {
            "intro": "H·ªá th·ªëng ƒëang g·∫∑p l·ªói!",
            "recommended_tools": [],
            "comparison": [],
            "final_recommendation": ["Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ƒë·∫∑t c√¢u h·ªèi kh√°c."],
            "next_steps": ["Th·ª≠ l·∫°i sau 5 ph√∫t"]
        }

# --- 4. QU·∫¢N L√ù SESSION (LOGIC M·ªöI ƒê·ªÇ FIX L·ªñI NH·ªö NH·∫¶M) ---

# Kho ch·ª©a c√°c phi√™n l√†m vi·ªác ri√™ng bi·ªát
_active_sessions = {}

def get_consultant(session_id):
    """L·∫•y bot ri√™ng c·ªßa session ƒë√≥, n·∫øu ch∆∞a c√≥ th√¨ t·∫°o m·ªõi"""
    global _active_sessions
    if session_id not in _active_sessions:
        print(f"üÜï Creating new memory for session: {session_id}")
        _active_sessions[session_id] = TechConsultant() # Bot m·ªõi s·∫Ω d√πng prompt g·ªëc ·ªü tr√™n
    return _active_sessions[session_id]

# --- 5. C√ÅC H√ÄM X·ª¨ L√ù CH√çNH (ƒê∆∞·ª£c Index.py g·ªçi) ---

def is_tool_query(query: str) -> bool:
    if not query: return False
    
    # Prompt ph√¢n lo·∫°i (Gi·ªØ nguy√™n logic c·ªßa b·∫°n)
    prompt = f"""
B·∫°n l√† m·ªôt m√¥-ƒëun PH√ÇN LO·∫†I c√¢u h·ªèi cho h·ªá th·ªëng t∆∞ v·∫•n c√¥ng c·ª•.

H·ªá th·ªëng c√≥ 2 ch·∫ø ƒë·ªô:
1) TOOLS: D√πng khi ng∆∞·ªùi d√πng mu·ªën ƒë∆∞·ª£c T√åM / CH·ªåN / G·ª¢I √ù / GI·ªöI THI·ªÜU / SO S√ÅNH / L·ª∞A CH·ªåN (ho·∫∑c ng·ªØ c·∫£nh t∆∞∆°ng t·ª±)
    cho c√¥ng c·ª•, ph·∫ßn m·ªÅm, ·ª©ng d·ª•ng, app, web, n·ªÅn t·∫£ng, ng√¥n ng·ªØ, d·ªãch v·ª•, kho√° h·ªçc online,...
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: TOOLS
2) CHAT: D√πng cho c√°c c√¢u h·ªèi c√≤n l·∫°i (ch√†o h·ªèi, h·ªèi ki·∫øn th·ª©c chung, small talk, h∆∞·ªõng d·∫´n nhanh,...)
=> Tr·∫£ l·ªùi t·ª´ kh√≥a DUY NH·∫§T: CHAT

B√¢y gi·ªù h√£y ph√¢n lo·∫°i c√¢u sau:

User: "{query}"
Assistant:
"""
    try:
        resp = _mode_classifier_model.invoke(prompt)
        text = (resp.content or "").strip().upper()
        print(f"‚ùî Request: '{query[:50]}...' -> Type: {text}")
        return "TOOLS" in text
    except:
        return False

def handle_query(query, session_id):
    """X·ª≠ l√Ω t√¨m tool (C√≥ session_id)"""
    consultant = get_consultant(session_id)
    return consultant.ask(query)

def general_chat(query, session_id):
    """X·ª≠ l√Ω chat th∆∞·ªùng (C√≥ session_id)"""
    consultant = get_consultant(session_id)
    return consultant.general_chat_with_memory(query)

def reset_consultation(session_id):
    """Reset phi√™n chat c·ª• th·ªÉ"""
    global _active_sessions
    if session_id in _active_sessions:
        _active_sessions[session_id].reset_conversation()
        return f"‚úÖ ƒê√£ reset b·ªô nh·ªõ cho session {session_id}!"
    return "‚ö†Ô∏è Session m·ªõi tinh."